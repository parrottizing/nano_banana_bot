"""
Handler for photo creation feature.
Handles the "Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾" menu option with support for text and image inputs.
"""
import logging
import io
from PIL import Image
from telegram import Update
from telegram.ext import ContextTypes
import google.generativeai as genai
from .prompt_classifier import analyze_user_intent

MODEL_NAME = "gemini-3-pro-image-preview"
MAX_IMAGES = 5
MAX_IMAGE_SIZE_MB = 7

# CTR optimization prompt enhancement (based on marketplace best practices 2025)
CTR_ENHANCEMENT_PROMPT = """
ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜ Ð’ÐÐ–ÐÐž: ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ñ…Ð¾Ñ‡ÐµÑ‚ ÑƒÐ»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ CTR (ÐºÐ»Ð¸ÐºÐ°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ) Ð´Ð»Ñ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¿Ð»ÐµÐ¹ÑÐ° (Wildberries, Ozon, Ð¯Ð½Ð´ÐµÐºÑ.ÐœÐ°Ñ€ÐºÐµÑ‚).

ÐŸÐ Ð˜ÐœÐ•ÐÐ¯Ð™ Ð¡Ð¢Ð ÐÐ¢Ð•Ð“Ð˜Ð® "Ð£ÐœÐÐžÐ“Ðž ÐœÐ˜ÐÐ˜ÐœÐÐ›Ð˜Ð—ÐœÐ" (2025):

**Ð’Ð˜Ð—Ð£ÐÐ›Ð¬ÐÐÐ¯ Ð˜Ð•Ð ÐÐ Ð¥Ð˜Ð¯:**
â€¢ Ð¢Ð¾Ð²Ð°Ñ€ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð·Ð°Ð½Ð¸Ð¼Ð°Ñ‚ÑŒ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 60-70% Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
â€¢ Ð§Ð¸ÑÑ‚Ñ‹Ð¹ Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹/Ð±ÐµÐ»Ñ‹Ð¹ Ñ„Ð¾Ð½ Ð´Ð»Ñ Ð²Ñ‹Ð´ÐµÐ»ÐµÐ½Ð¸Ñ ÑÑ€ÐµÐ´Ð¸ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð²
â€¢ Ð¢Ð¾Ð²Ð°Ñ€ Ð² Ñ†ÐµÐ½Ñ‚Ñ€Ðµ ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ð¾ÑÑ‚ÑŒÑŽ Ð´ÐµÑ‚Ð°Ð»ÐµÐ¹
â€¢ Ð’Ñ‹ÑÐ¾ÐºÐ¸Ð¹ ÐºÐ¾Ð½Ñ‚Ñ€Ð°ÑÑ‚ Ð¼ÐµÐ¶Ð´Ñƒ Ñ‚Ð¾Ð²Ð°Ñ€Ð¾Ð¼ Ð¸ Ñ„Ð¾Ð½Ð¾Ð¼

**Ð¢Ð˜ÐŸÐžÐ“Ð ÐÐ¤Ð˜ÐšÐ Ð˜ Ð¢Ð•ÐšÐ¡Ð¢:**
â€¢ Ð¢Ð¾Ð»ÑŒÐºÐ¾ 1-2 ÐšÐ Ð£ÐŸÐÐ«Ð¥ Ñ‚ÐµÐ·Ð¸ÑÐ° (Ð¶Ð¸Ñ€Ð½Ñ‹Ð¹ ÑˆÑ€Ð¸Ñ„Ñ‚ Ð±ÐµÐ· Ð·Ð°ÑÐµÑ‡ÐµÐº)
â€¢ Ð§Ð¸Ñ‚Ð°ÐµÐ¼Ð¾ÑÑ‚ÑŒ Ð½Ð° Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ñ… ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð°Ñ… (80%+ Ñ‚Ñ€Ð°Ñ„Ð¸ÐºÐ°)
â€¢ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¤ÐÐšÐ¢Ð« Ð²Ð¼ÐµÑÑ‚Ð¾ ÑÑƒÐ±ÑŠÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¾Ñ†ÐµÐ½Ð¾Ðº: "5000 Ð¿Ñ€Ð¾Ð´Ð°Ð¶", "Ð ÐµÐ¹Ñ‚Ð¸Ð½Ð³ 4.9" Ð²Ð¼ÐµÑÑ‚Ð¾ "Ð›ÑƒÑ‡ÑˆÐ¸Ð¹"
â€¢ ÐÐ• Ñ€Ð°Ð·Ð¼ÐµÑ‰Ð°Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð² ÑÐ»ÐµÐ¿Ñ‹Ñ… Ð·Ð¾Ð½Ð°Ñ…: Ð²ÐµÑ€Ñ…Ð½Ð¸Ðµ ÑƒÐ³Ð»Ñ‹, Ð½Ð¸Ð¶Ð½ÑÑ Ñ‡Ð°ÑÑ‚ÑŒ (Ñ‚Ð°Ð¼ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ WB)

**Ð¦Ð’Ð•Ð¢ÐžÐ’ÐÐ¯ Ð¡Ð¢Ð ÐÐ¢Ð•Ð“Ð˜Ð¯:**
â€¢ ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð½Ð°Ñ Ð¿Ð°Ð»Ð¸Ñ‚Ñ€Ð°: Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ†Ð²ÐµÑ‚ Ð±Ñ€ÐµÐ½Ð´Ð° + 1 Ð°ÐºÑ†ÐµÐ½Ñ‚Ð½Ñ‹Ð¹ Ñ†Ð²ÐµÑ‚
â€¢ Ð˜Ð·Ð±ÐµÐ³Ð°Ð¹ ÐºÐ¸ÑÐ»Ð¾Ñ‚Ð½Ñ‹Ñ…/ÐºÑ€Ð¸Ñ‡Ð°Ñ‰Ð¸Ñ… Ñ†Ð²ÐµÑ‚Ð¾Ð² (ÑƒÑÑ‚Ð°Ñ€ÐµÐ²ÑˆÐ¸Ð¹ Ñ‚Ñ€ÐµÐ½Ð´)
â€¢ Ð¦Ð²ÐµÑ‚Ð° Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð²Ñ‹Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ Ð´Ð¾Ð²ÐµÑ€Ð¸Ðµ Ð¸ Ð¿Ñ€ÐµÐ¼Ð¸Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ

**Ð¢Ð•Ð¥ÐÐ˜Ð§Ð•Ð¡ÐšÐ˜Ð• Ð¢Ð Ð•Ð‘ÐžÐ’ÐÐÐ˜Ð¯:**
â€¢ Ð¡Ð¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ ÑÑ‚Ð¾Ñ€Ð¾Ð½: ÑÑ‚Ñ€Ð¾Ð³Ð¾ 3:4 (Ð²ÐµÑ€Ñ‚Ð¸ÐºÐ°Ð»ÑŒÐ½Ð°Ñ Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ)
â€¢ Ð’Ñ‹ÑÐ¾ÐºÐ¾Ðµ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð·ÑƒÐ¼Ð° (Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 1000x1000px)
â€¢ Ð¢Ð¾Ð²Ð°Ñ€ Ð·Ð°Ð½Ð¸Ð¼Ð°ÐµÑ‚ ÐÐ• ÐœÐ•ÐÐ•Ð• 20% Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸ (Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ðµ WB)

**ÐŸÐ¡Ð˜Ð¥ÐžÐ›ÐžÐ“Ð˜Ð¯ Ð’ÐžÐ¡ÐŸÐ Ð˜Ð¯Ð¢Ð˜Ð¯:**
â€¢ Ð¤Ð¾ÐºÑƒÑ Ð½Ð° ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… Ð¿Ñ€ÐµÐ¸Ð¼ÑƒÑ‰ÐµÑÑ‚Ð²Ð°Ñ… Ñ‚Ð¾Ð²Ð°Ñ€Ð° (Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð», Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ñ, Ð£Ð¢ÐŸ)
â€¢ Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð²Ñ‹Ð³Ð¾Ð´Ñ‹ Ð´Ð»Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° (Ð½Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ "Ð²Ð¾Ð´Ð¾Ð½ÐµÐ¿Ñ€Ð¾Ð½Ð¸Ñ†Ð°ÐµÐ¼Ñ‹Ð¹", Ð° "Ð·Ð°Ñ‰Ð¸Ñ‚Ð° Ð² Ð´Ð¾Ð¶Ð´ÑŒ Ð´Ð¾ -30Â°C")
â€¢ ÐÐºÑ†ÐµÐ½Ñ‚ Ð½Ð° 1-2 Ð³Ð»Ð°Ð²Ð½Ñ‹Ñ… Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ°Ñ…, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ€ÐµÑˆÐ°ÑŽÑ‚ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ Ð¿Ð¾ÐºÑƒÐ¿Ð°Ñ‚ÐµÐ»Ñ

**Ð—ÐÐŸÐ Ð•Ð©Ð•ÐÐž:**
â€¢ Ð Ð°Ð·Ð¼Ñ‹Ñ‚Ñ‹Ðµ/Ð¿ÐµÑ€ÐµÐ³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸
â€¢ ÐœÐ½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾ Ð¼ÐµÐ»ÐºÐ¸Ñ… Ð½Ð°Ð´Ð¿Ð¸ÑÐµÐ¹ Ð¸ Ð·Ð½Ð°Ñ‡ÐºÐ¾Ð² ("Ð¥Ð˜Ð¢", "Ð¡ÐšÐ˜Ð”ÐšÐ" Ð¸ Ñ‚.Ð¿.)
â€¢ Ð£ÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ñ†ÐµÐ½Ñ‹ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸
â€¢ ÐŸÐµÑ€ÐµÐºÑ€Ñ‹Ñ‚Ð¸Ðµ Ñ‚Ð¾Ð²Ð°Ñ€Ð° Ð¸Ð·Ð±Ñ‹Ñ‚Ð¾Ñ‡Ð½Ð¾Ð¹ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð¹
â€¢ Ð¡ÑƒÐ±ÑŠÐµÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¿Ñ€ÐµÐ²Ð¾ÑÑ…Ð¾Ð´Ð½Ñ‹Ðµ ÑÑ‚ÐµÐ¿ÐµÐ½Ð¸ Ð±ÐµÐ· Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ

Ð¦Ð•Ð›Ð¬: Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ, ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð¼Ð³Ð½Ð¾Ð²ÐµÐ½Ð½Ð¾ Ð¿Ñ€Ð¸Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ, Ð¿ÐµÑ€ÐµÐ´Ð°ÐµÑ‚ ÑÑƒÑ‚ÑŒ Ñ‚Ð¾Ð²Ð°Ñ€Ð° Ð·Ð° 0.5 ÑÐµÐºÑƒÐ½Ð´Ñ‹ Ð¿Ñ€Ð¾ÑÐ¼Ð¾Ñ‚Ñ€Ð° Ð¸ Ð²Ñ‹Ð·Ñ‹Ð²Ð°ÐµÑ‚ Ð¶ÐµÐ»Ð°Ð½Ð¸Ðµ ÐºÐ»Ð¸ÐºÐ½ÑƒÑ‚ÑŒ Ð´Ð»Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´ÐµÑ‚Ð°Ð»ÐµÐ¹.
"""

# Screenshot-specific prompt enhancement  
SCREENSHOT_ENHANCEMENT_PROMPT = """
ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜ Ð’ÐÐ–ÐÐž: Ð­Ñ‚Ð¾ ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¿Ð»ÐµÐ¹ÑÐ° Ñ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ°.

Ð—ÐÐ”ÐÐ§Ð: Ð˜Ð·Ð²Ð»ÐµÑ‡ÑŒ Ñ‡Ð¸ÑÑ‚Ð¾Ðµ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ‚Ð¾Ð²Ð°Ñ€Ð° Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¹ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸.

**Ð§Ð¢Ðž ÐÐ£Ð–ÐÐž Ð£Ð”ÐÐ›Ð˜Ð¢Ð¬:**
â€¢ ÐÐ°Ð²Ð¸Ð³Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ Ð¿Ð°Ð½ÐµÐ»Ð¸ (Ð²ÐµÑ€Ñ…Ð½ÑÑ/Ð½Ð¸Ð¶Ð½ÑÑ)
â€¢ ÐšÐ½Ð¾Ð¿ÐºÐ¸ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ° ("ÐšÑƒÐ¿Ð¸Ñ‚ÑŒ", "Ð’ ÐºÐ¾Ñ€Ð·Ð¸Ð½Ñƒ", "Ð˜Ð·Ð±Ñ€Ð°Ð½Ð½Ð¾Ðµ")
â€¢ Ð¤Ð¸Ð»ÑŒÑ‚Ñ€Ñ‹ Ð¸ Ð¼ÐµÐ½ÑŽ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¿Ð»ÐµÐ¹ÑÐ°
â€¢ Ð›Ð¾Ð³Ð¾Ñ‚Ð¸Ð¿Ñ‹ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¿Ð»ÐµÐ¹ÑÐ° (Wildberries, Ozon, Ð¯Ð½Ð´ÐµÐºÑ.ÐœÐ°Ñ€ÐºÐµÑ‚ Ð¸ Ð´Ñ€.)
â€¢ URL-Ð°Ð´Ñ€ÐµÑÐ° Ð¸ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹ Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð°
â€¢ Ð‘Ð»Ð¾ÐºÐ¸ Ñ Ð¾Ñ‚Ð·Ñ‹Ð²Ð°Ð¼Ð¸ Ð¸ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³Ð°Ð¼Ð¸
â€¢ Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ Ð¿Ð»Ð°ÑˆÐºÐ¸ ("ÐÐ¾Ð²Ð¸Ð½ÐºÐ°", "Ð¥Ð¸Ñ‚", Ð¿Ñ€Ð¾Ð¼Ð¾-Ð±Ð°Ð½Ð½ÐµÑ€Ñ‹)
â€¢ Ð”Ñ€ÑƒÐ³Ð¸Ðµ Ñ‚Ð¾Ð²Ð°Ñ€Ñ‹ Ð² Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÑ…

**Ð§Ð¢Ðž ÐÐ£Ð–ÐÐž Ð¡ÐžÐ¥Ð ÐÐÐ˜Ð¢Ð¬/Ð£Ð›Ð£Ð§Ð¨Ð˜Ð¢Ð¬:**
â€¢ Ð¡Ð°Ð¼Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ‚Ð¾Ð²Ð°Ñ€Ð° Ð² Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ð¼ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ðµ
â€¢ Ð’Ð°Ð¶Ð½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ñ‚Ð¾Ð²Ð°Ñ€Ðµ (ÐµÑÐ»Ð¸ Ð¾Ð½Ð° Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° Ð² Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ)
â€¢ ÐšÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ†Ð¸ÑŽ Ñ‚Ð¾Ð²Ð°Ñ€Ð°, Ð½Ð¾ ÑƒÐ»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ ÐµÑ‘ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð²Ð¸Ð´Ð°

**ÐšÐÐš ÐžÐ‘Ð ÐÐ‘ÐžÐ¢ÐÐ¢Ð¬:**
â€¢ Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ñ‡Ð¸ÑÑ‚Ñ‹Ð¹ Ð±ÐµÐ»Ñ‹Ð¹/Ð½ÐµÐ¹Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ„Ð¾Ð½
â€¢ Ð Ð°Ð·Ð¼ÐµÑÑ‚Ð¸Ñ‚ÑŒ Ñ‚Ð¾Ð²Ð°Ñ€ Ð¿Ð¾ Ñ†ÐµÐ½Ñ‚Ñ€Ñƒ Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼ ÑÐ¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸ÐµÐ¼ 3:4
â€¢ ÐžÐ±ÐµÑÐ¿ÐµÑ‡Ð¸Ñ‚ÑŒ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ðµ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ (Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 1000x1000px)
â€¢ Ð£Ð»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ ÐºÐ¾Ð½Ñ‚Ñ€Ð°ÑÑ‚ Ð¸ Ñ€ÐµÐ·ÐºÐ¾ÑÑ‚ÑŒ Ñ‚Ð¾Ð²Ð°Ñ€Ð°
â€¢ Ð£Ð±ÐµÐ´Ð¸Ñ‚ÑŒÑÑ, Ñ‡Ñ‚Ð¾ Ñ‚Ð¾Ð²Ð°Ñ€ Ð·Ð°Ð½Ð¸Ð¼Ð°ÐµÑ‚ 60-70% Ð¿Ð»Ð¾Ñ‰Ð°Ð´Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ

Ð¦Ð•Ð›Ð¬: ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ñ‚ÑŒ ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚ Ð² Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ‚Ð¾Ð²Ð°Ñ€Ð½Ð¾Ð¹ ÐºÐ°Ñ€Ñ‚Ð¾Ñ‡ÐºÐ¸, Ð³Ð¾Ñ‚Ð¾Ð²Ð¾Ðµ Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð½Ð° Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¿Ð»ÐµÐ¹Ñ.
"""

# Store user states for conversation flow
user_states = {}

async def create_photo_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Called when user clicks 'Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ñ„Ð¾Ñ‚Ð¾' button"""
    query = update.callback_query
    await query.answer()
    
    user_id = update.effective_user.id
    user_states[user_id] = {
        "mode": "awaiting_photo_input",
        "images": []
    }
    
    await query.message.reply_text(
        "ðŸŽ¨ *Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ„Ð¾Ñ‚Ð¾*\\n\\n"
        "ÐžÑ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ, ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¸Ð»Ð¸ Ð¾Ñ‚Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ.\\n"
        "ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: _'ÐšÑ€Ð°ÑÐ¸Ð²Ñ‹Ð¹ Ð·Ð°ÐºÐ°Ñ‚ Ð½Ð°Ð´ Ð³Ð¾Ñ€Ð°Ð¼Ð¸ Ñ Ð¾Ñ‚Ñ€Ð°Ð¶ÐµÐ½Ð¸ÐµÐ¼ Ð² Ð¾Ð·ÐµÑ€Ðµ'_",
        parse_mode="Markdown"
    )

async def handle_create_photo_image(update: Update, context: ContextTypes.DEFAULT_TYPE) -> bool:
    """
    Handle incoming images when user is in photo creation mode.
    Returns True if the message was handled, False otherwise.
    """
    user_id = update.effective_user.id
    
    # Check if user is in photo creation mode
    if user_id not in user_states or user_states[user_id].get("mode") != "awaiting_photo_input":
        return False
    
    # Check if image has caption
    caption = update.message.caption
    if not caption:
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text="âš ï¸ ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ñ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¼ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÐµÐ¼ Ð² Ð¿Ð¾Ð´Ð¿Ð¸ÑÐ¸.\\n\\n"
                 "ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Ð´Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑŒ _'Ð´Ð¾Ð±Ð°Ð²ÑŒ ÑˆÐ»ÑÐ¿Ñƒ ÑÑ‚Ð¾Ð¼Ñƒ ÐºÐ¾Ñ‚Ñƒ'_ Ðº Ð²Ð°ÑˆÐµÐ¼Ñƒ Ñ„Ð¾Ñ‚Ð¾.",
            parse_mode="Markdown"
        )
        return True
    
    # Check image limit
    current_images = user_states[user_id].get("images", [])
    if len(current_images) >= MAX_IMAGES:
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text=f"âš ï¸ Ð”Ð¾ÑÑ‚Ð¸Ð³Ð½ÑƒÑ‚ Ð»Ð¸Ð¼Ð¸Ñ‚ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ ({MAX_IMAGES}). ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ..."
        )
        # Process with current images
        await _process_image_generation(update, context, caption, current_images)
        user_states.pop(user_id, None)
        return True
    
    try:
        # Get the largest photo size
        photo = update.message.photo[-1]
        
        # Check file size (Telegram gives size in bytes)
        file_size_mb = photo.file_size / (1024 * 1024) if photo.file_size else 0
        if file_size_mb > MAX_IMAGE_SIZE_MB:
            await context.bot.send_message(
                chat_id=update.effective_chat.id,
                text=f"âš ï¸ Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ðµ ({file_size_mb:.1f}MB). ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ {MAX_IMAGE_SIZE_MB}MB."
            )
            return True
        
        # Download the image
        file = await photo.get_file()
        image_bytes = await file.download_as_bytearray()
        
        # Open with PIL to ensure proper format
        image = Image.open(io.BytesIO(image_bytes))
        
        # Store PIL Image object (compatible with google.generativeai)
        current_images.append(image)
        user_states[user_id]["images"] = current_images
        
        logging.info(f"[CreatePhoto] User {user_id} added image {len(current_images)}/{MAX_IMAGES}")
        
        # Process immediately with the caption
        await _process_image_generation(update, context, caption, current_images)
        user_states.pop(user_id, None)
        
    except Exception as e:
        logging.error(f"[CreatePhoto] Error downloading image: {e}", exc_info=True)
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text=f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: {e}"
        )
    
    return True

async def handle_photo_prompt(update: Update, context: ContextTypes.DEFAULT_TYPE) -> bool:
    """
    Handle incoming text when user is in photo creation mode.
    Returns True if the message was handled, False otherwise.
    """
    user_id = update.effective_user.id
    
    # Check if user is in photo creation mode
    if user_id not in user_states or user_states[user_id].get("mode") != "awaiting_photo_input":
        return False
    
    user_prompt = update.message.text
    chat_id = update.effective_chat.id
    
    # Get any images the user might have sent
    user_images = user_states[user_id].get("images", [])
    
    # Clear the state
    user_states.pop(user_id, None)
    
    # Process with text only or text + images
    await _process_image_generation(update, context, user_prompt, user_images)
    
    return True

async def _process_image_generation(update: Update, context: ContextTypes.DEFAULT_TYPE, 
                                   prompt: str, images: list):
    """
    Internal function to process image generation with optional image inputs.
    
    Args:
        update: Telegram update
        context: Telegram context
        prompt: Text prompt from user
        images: List of PIL Image objects (can be empty)
    """
    chat_id = update.effective_chat.id
    
    # Send processing message
    processing_msg = "ðŸŽ¨ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ..."
    if images:
        img_count = len(images)
        if img_count == 1:
            processing_msg = "ðŸŽ¨ ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ..."
        elif img_count < 5:
            processing_msg = f"ðŸŽ¨ ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ {img_count} Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ..."
        else:
            processing_msg = f"ðŸŽ¨ ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ {img_count} Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹..."
    
    await context.bot.send_message(
        chat_id=chat_id, 
        text=processing_msg
    )
    
    try:
        # Analyze user intent using Gemma 3 12B classifier
        intent = await analyze_user_intent(prompt, images)
        
        logging.info(f"[CreatePhoto] Intent analysis: CTR={intent['wants_ctr_improvement']}, "
                    f"Screenshot={intent['is_screenshot']}")
        
        # Build enhanced prompt based on classification
        enhanced_prompt = prompt
        
        if intent['wants_ctr_improvement']:
            enhanced_prompt += CTR_ENHANCEMENT_PROMPT
            logging.info("[CreatePhoto] Added CTR optimization enhancement")
        
        if intent['is_screenshot']:
            enhanced_prompt += SCREENSHOT_ENHANCEMENT_PROMPT
            logging.info("[CreatePhoto] Added screenshot processing enhancement")
        
        model = genai.GenerativeModel(MODEL_NAME)
        logging.info(f"[CreatePhoto] Generating with prompt: {prompt}, images: {len(images)}")
        
        # Build the content for multimodal input
        # For google.generativeai, we pass images and text directly in a list
        if images:
            # Multi-modal: images + enhanced text
            content = images + [enhanced_prompt]
        else:
            # Text-only
            content = enhanced_prompt
        
        # Generate content
        response = await model.generate_content_async(content)
        
        has_content = False

        # Check for image parts
        if hasattr(response, 'parts'):
            for part in response.parts:
                if hasattr(part, 'inline_data') and part.inline_data:
                    logging.info(f"[CreatePhoto] Found image with mime_type: {part.inline_data.mime_type}")
                    image_data = part.inline_data.data
                    
                    caption_text = "ðŸŽ¨ Ð’Ð°ÑˆÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾!\n\n"
                    if images:
                        caption_text += f"ðŸ“¸ Ð˜ÑÑ…Ð¾Ð´Ð½Ñ‹Ñ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹: {len(images)}\n"
                    caption_text += f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚: _{prompt}_"
                    
                    # Send as photo for quick preview (Telegram will compress)
                    await context.bot.send_photo(
                        chat_id=chat_id, 
                        photo=io.BytesIO(image_data),
                        caption=caption_text,
                        parse_mode="Markdown"
                    )
                    
                    # Send as document for full quality
                    await context.bot.send_document(
                        chat_id=chat_id,
                        document=io.BytesIO(image_data),
                        filename="generated_image.png",
                        caption="ðŸ“¥ Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð² Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð¼ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ðµ"
                    )
                    has_content = True

        # Check for text response
        try:
            if response.text:
                await context.bot.send_message(chat_id=chat_id, text=response.text)
                has_content = True
        except ValueError:
            pass

        if not has_content:
            await context.bot.send_message(
                chat_id=chat_id, 
                text="âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ."
            )
        
    except Exception as e:
        logging.error(f"[CreatePhoto] Error: {e}", exc_info=True)
        await context.bot.send_message(chat_id=chat_id, text=f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {e}")
