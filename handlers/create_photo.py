"""
Handler for photo creation feature.
Handles the "–°–æ–∑–¥–∞—Ç—å —Ñ–æ—Ç–æ" menu option with support for text and image inputs.
"""
import logging
import io
import asyncio
from PIL import Image
from telegram import Update
from telegram.ext import ContextTypes
import google.generativeai as genai
from .prompt_classifier import analyze_user_intent
from database import (
    get_user_state, set_user_state, clear_user_state,
    log_conversation, check_balance, deduct_balance,
    update_user_balance, TOKEN_COSTS
)

MODEL_NAME = "gemini-3-pro-image-preview"
MAX_IMAGES = 5
MAX_IMAGE_SIZE_MB = 7

# Animation configuration
PHOTO_LOADING_EMOJIS = ["ü§î", "üí°", "üé®"]
ANIMATION_STEP_DELAY = 2.9  # Seconds between emoji changes

async def run_loading_animation(context: ContextTypes.DEFAULT_TYPE, chat_id: int):
    """
    Runs a cycling loading animation that sends, edits, and deletes messages.
    Expected to be cancelled when processing is complete.
    """
    try:
        while True:
            # Step 1: Send initial message
            msg = await context.bot.send_message(
                chat_id=chat_id, 
                text=PHOTO_LOADING_EMOJIS[0]
            )
            
            # Step 2: Cycle through rest of emojis
            for emoji in PHOTO_LOADING_EMOJIS[1:]:
                await asyncio.sleep(ANIMATION_STEP_DELAY)
                try:
                    await context.bot.edit_message_text(
                        chat_id=chat_id,
                        message_id=msg.message_id,
                        text=emoji
                    )
                except Exception:
                    # Ignore edit errors (e.g. if message was deleted)
                    pass
            
            # Step 3: Wait a bit before deleting (cycle complete)
            await asyncio.sleep(ANIMATION_STEP_DELAY)
            
            # Step 4: Delete message
            try:
                await context.bot.delete_message(
                    chat_id=chat_id,
                    message_id=msg.message_id
                )
            except Exception:
                pass
                
            # Loop continues immediately to send next message
            
    except asyncio.CancelledError:
        # Cleanup when cancelled: try to delete the last message
        try:
            if 'msg' in locals():
                await context.bot.delete_message(
                    chat_id=chat_id, 
                    message_id=msg.message_id
                )
        except Exception:
            pass
        raise

# CTR optimization prompt enhancement (based on marketplace best practices 2025)
CTR_ENHANCEMENT_PROMPT = """
–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç —É–ª—É—á—à–∏—Ç—å CTR (–∫–ª–∏–∫–∞–±–µ–ª—å–Ω–æ—Å—Ç—å) –¥–ª—è –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞ (Wildberries, Ozon, –Ø–Ω–¥–µ–∫—Å.–ú–∞—Ä–∫–µ—Ç).

–ü–†–ò–ú–ï–ù–Ø–ô –°–¢–†–ê–¢–ï–ì–ò–Æ "–£–ú–ù–û–ì–û –ú–ò–ù–ò–ú–ê–õ–ò–ó–ú–ê" (2025):

**–í–ò–ó–£–ê–õ–¨–ù–ê–Ø –ò–ï–†–ê–†–•–ò–Ø:**
‚Ä¢ –¢–æ–≤–∞—Ä –¥–æ–ª–∂–µ–Ω –∑–∞–Ω–∏–º–∞—Ç—å –º–∏–Ω–∏–º—É–º 60-70% –ø–ª–æ—â–∞–¥–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
‚Ä¢ –¢–æ–≤–∞—Ä –≤ —Ü–µ–Ω—Ç—Ä–µ –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç—å—é –¥–µ—Ç–∞–ª–µ–π
‚Ä¢ –í—ã—Å–æ–∫–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç –º–µ–∂–¥—É —Ç–æ–≤–∞—Ä–æ–º –∏ —Ñ–æ–Ω–æ–º

**–¢–ò–ü–û–ì–†–ê–§–ò–ö–ê –ò –¢–ï–ö–°–¢:**
‚Ä¢ –¢–æ–ª—å–∫–æ 1-2 –ö–†–£–ü–ù–´–• —Ç–µ–∑–∏—Å–∞ (–∂–∏—Ä–Ω—ã–π —à—Ä–∏—Ñ—Ç –±–µ–∑ –∑–∞—Å–µ—á–µ–∫)
‚Ä¢ –ß–∏—Ç–∞–µ–º–æ—Å—Ç—å –Ω–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö (80%+ —Ç—Ä–∞—Ñ–∏–∫–∞)
‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π –§–ê–ö–¢–´ –≤–º–µ—Å—Ç–æ —Å—É–±—ä–µ–∫—Ç–∏–≤–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫: "5000 –ø—Ä–æ–¥–∞–∂", "–†–µ–π—Ç–∏–Ω–≥ 4.9" –≤–º–µ—Å—Ç–æ "–õ—É—á—à–∏–π"
‚Ä¢ –ù–ï —Ä–∞–∑–º–µ—â–∞–π —Ç–µ–∫—Å—Ç –≤ —Å–ª–µ–ø—ã—Ö –∑–æ–Ω–∞—Ö: –≤–µ—Ä—Ö–Ω–∏–µ —É–≥–ª—ã, –Ω–∏–∂–Ω—è—è —á–∞—Å—Ç—å (—Ç–∞–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å WB)

**–¶–í–ï–¢–û–í–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø:**
‚Ä¢ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –ø–∞–ª–∏—Ç—Ä–∞: –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–≤–µ—Ç –±—Ä–µ–Ω–¥–∞ + 1 –∞–∫—Ü–µ–Ω—Ç–Ω—ã–π —Ü–≤–µ—Ç
‚Ä¢ –ò–∑–±–µ–≥–∞–π –∫–∏—Å–ª–æ—Ç–Ω—ã—Ö/–∫—Ä–∏—á–∞—â–∏—Ö —Ü–≤–µ—Ç–æ–≤ (—É—Å—Ç–∞—Ä–µ–≤—à–∏–π —Ç—Ä–µ–Ω–¥)
‚Ä¢ –¶–≤–µ—Ç–∞ –¥–æ–ª–∂–Ω—ã –≤—ã–∑—ã–≤–∞—Ç—å –¥–æ–≤–µ—Ä–∏–µ –∏ –ø—Ä–µ–º–∏–∞–ª—å–Ω–æ—Å—Ç—å

**–¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:**
‚Ä¢ –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω: —Å—Ç—Ä–æ–≥–æ 3:4 (–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è)
‚Ä¢ –í—ã—Å–æ–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∑—É–º–∞ (–º–∏–Ω–∏–º—É–º 1000x1000px)
‚Ä¢ –¢–æ–≤–∞—Ä –∑–∞–Ω–∏–º–∞–µ—Ç –ù–ï –ú–ï–ù–ï–ï 20% –ø–ª–æ—â–∞–¥–∏ (—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ WB)

**–ü–°–ò–•–û–õ–û–ì–ò–Ø –í–û–°–ü–†–ò–Ø–¢–ò–Ø:**
‚Ä¢ –§–æ–∫—É—Å –Ω–∞ –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞—Ö —Ç–æ–≤–∞—Ä–∞ (–º–∞—Ç–µ—Ä–∏–∞–ª, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è, –£–¢–ü)
‚Ä¢ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã–≥–æ–¥—ã –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ (–Ω–µ –ø—Ä–æ—Å—Ç–æ "–≤–æ–¥–æ–Ω–µ–ø—Ä–æ–Ω–∏—Ü–∞–µ–º—ã–π", –∞ "–∑–∞—â–∏—Ç–∞ –≤ –¥–æ–∂–¥—å –¥–æ -30¬∞C")
‚Ä¢ –ê–∫—Ü–µ–Ω—Ç –Ω–∞ 1-2 –≥–ª–∞–≤–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ—à–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—É –ø–æ–∫—É–ø–∞—Ç–µ–ª—è

**–ó–ê–ü–†–ï–©–ï–ù–û:**
‚Ä¢ –†–∞–∑–º—ã—Ç—ã–µ/–ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏
‚Ä¢ –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –º–µ–ª–∫–∏—Ö –Ω–∞–¥–ø–∏—Å–µ–π –∏ –∑–Ω–∞—á–∫–æ–≤ ("–•–ò–¢", "–°–ö–ò–î–ö–ê" –∏ —Ç.–ø.)
‚Ä¢ –£–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
‚Ä¢ –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏–∑–±—ã—Ç–æ—á–Ω–æ–π –≥—Ä–∞—Ñ–∏–∫–æ–π
‚Ä¢ –°—É–±—ä–µ–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—ã–µ —Å—Ç–µ–ø–µ–Ω–∏ –±–µ–∑ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è

–¶–ï–õ–¨: –°–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –º–≥–Ω–æ–≤–µ–Ω–Ω–æ –ø—Ä–∏–≤–ª–µ–∫–∞–µ—Ç –≤–Ω–∏–º–∞–Ω–∏–µ, –ø–µ—Ä–µ–¥–∞–µ—Ç —Å—É—Ç—å —Ç–æ–≤–∞—Ä–∞ –∑–∞ 0.5 —Å–µ–∫—É–Ω–¥—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏ –≤—ã–∑—ã–≤–∞–µ—Ç –∂–µ–ª–∞–Ω–∏–µ –∫–ª–∏–∫–Ω—É—Ç—å –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π.
"""



async def create_photo_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Called when user clicks '–°–æ–∑–¥–∞—Ç—å —Ñ–æ—Ç–æ' button or uses /create_photo command"""
    from database import get_user
    
    user_id = update.effective_user.id
    
    # Set user state in database
    set_user_state(user_id, "create_photo", "awaiting_photo_input", {"images": []})
    
    # Log the button click
    log_conversation(user_id, "create_photo", "button_click", "create_photo")
    
    # Get user balance for display
    user = get_user(user_id)
    balance = user['balance'] if user else 0
    cost = TOKEN_COSTS["create_photo"]
    
    message_text = (
        "üé® *–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–æ—Ç–æ*\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ —Ö–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å –∏–ª–∏ –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å.\n\n"
        f"_–°—Ç–æ–∏–º–æ—Å—Ç—å: {cost} —Ç–æ–∫–µ–Ω–æ–≤_\n"
        f"_–í–∞—à –±–∞–ª–∞–Ω—Å: {balance} —Ç–æ–∫–µ–Ω–æ–≤_"
    )
    
    # Check if this is a callback query (inline button) or a command
    if update.callback_query:
        query = update.callback_query
        await query.answer()
        await query.message.reply_text(message_text, parse_mode="Markdown")
    else:
        # This is a direct command (from menu or typed)
        await update.message.reply_text(message_text, parse_mode="Markdown")

async def handle_create_photo_image(update: Update, context: ContextTypes.DEFAULT_TYPE) -> bool:
    """
    Handle incoming images when user is in photo creation mode.
    Returns True if the message was handled, False otherwise.
    """
    user_id = update.effective_user.id
    
    # Check if user is in photo creation mode (using database)
    state = get_user_state(user_id)
    if not state or state.get("feature") != "create_photo" or state.get("state") != "awaiting_photo_input":
        return False
    
    # Check if image has caption
    caption = update.message.caption
    if not caption:
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text="‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º –≤ –ø–æ–¥–ø–∏—Å–∏.\\n\\n"
                 "–ù–∞–ø—Ä–∏–º–µ—Ä: –¥–æ–±–∞–≤—å—Ç–µ –ø–æ–¥–ø–∏—Å—å _'–¥–æ–±–∞–≤—å —à–ª—è–ø—É —ç—Ç–æ–º—É –∫–æ—Ç—É'_ –∫ –≤–∞—à–µ–º—É —Ñ–æ—Ç–æ.",
            parse_mode="Markdown"
        )
        return True
    
    # Check balance before processing
    if not check_balance(user_id, TOKEN_COSTS["create_photo"]):
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text=f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤! –¢—Ä–µ–±—É–µ—Ç—Å—è: {TOKEN_COSTS['create_photo']}\n"
                 "–ü–æ–ø–æ–ª–Ω–∏—Ç–µ –±–∞–ª–∞–Ω—Å –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è."
        )
        clear_user_state(user_id)
        return True
    
    # Get current images from state (note: images are not persisted to DB, only count)
    # For now we handle images in-memory within one session
    current_images = context.user_data.get("pending_images", [])
    if len(current_images) >= MAX_IMAGES:
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text=f"‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({MAX_IMAGES}). –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é..."
        )
        # Process with current images
        await _process_image_generation(update, context, caption, current_images)
        clear_user_state(user_id)
        context.user_data.pop("pending_images", None)
        return True
    
    try:
        # Get the largest photo size
        photo = update.message.photo[-1]
        
        # Check file size (Telegram gives size in bytes)
        file_size_mb = photo.file_size / (1024 * 1024) if photo.file_size else 0
        if file_size_mb > MAX_IMAGE_SIZE_MB:
            await context.bot.send_message(
                chat_id=update.effective_chat.id,
                text=f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ ({file_size_mb:.1f}MB). –ú–∞–∫—Å–∏–º—É–º {MAX_IMAGE_SIZE_MB}MB."
            )
            return True
        
        # Download the image
        file = await photo.get_file()
        image_bytes = await file.download_as_bytearray()
        
        # Open with PIL to ensure proper format
        image = Image.open(io.BytesIO(image_bytes))
        
        # Store PIL Image object in context.user_data (temporary storage)
        current_images.append(image)
        context.user_data["pending_images"] = current_images
        
        logging.info(f"[CreatePhoto] User {user_id} added image {len(current_images)}/{MAX_IMAGES}")
        
        # Process immediately with the caption
        await _process_image_generation(update, context, caption, current_images)
        clear_user_state(user_id)
        context.user_data.pop("pending_images", None)
        
    except Exception as e:
        logging.error(f"[CreatePhoto] Error downloading image: {e}", exc_info=True)
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text=f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}"
        )
        log_conversation(user_id, "create_photo", "error", str(e), success=False)
    
    return True

async def handle_photo_prompt(update: Update, context: ContextTypes.DEFAULT_TYPE) -> bool:
    """
    Handle incoming text when user is in photo creation mode.
    Returns True if the message was handled, False otherwise.
    """
    user_id = update.effective_user.id
    
    # Check if user is in photo creation mode (using database)
    state = get_user_state(user_id)
    if not state or state.get("feature") != "create_photo" or state.get("state") != "awaiting_photo_input":
        return False
    
    # Check balance before processing
    if not check_balance(user_id, TOKEN_COSTS["create_photo"]):
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text=f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤! –¢—Ä–µ–±—É–µ—Ç—Å—è: {TOKEN_COSTS['create_photo']}\n"
                 "–ü–æ–ø–æ–ª–Ω–∏—Ç–µ –±–∞–ª–∞–Ω—Å –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è."
        )
        clear_user_state(user_id)
        return True
    
    user_prompt = update.message.text
    chat_id = update.effective_chat.id
    
    # Get any images the user might have sent (from context.user_data)
    user_images = context.user_data.get("pending_images", [])
    
    # Clear the state
    clear_user_state(user_id)
    context.user_data.pop("pending_images", None)
    
    # Process with text only or text + images
    await _process_image_generation(update, context, user_prompt, user_images)
    
    return True

async def _process_image_generation(update: Update, context: ContextTypes.DEFAULT_TYPE, 
                                   prompt: str, images: list):
    """
    Internal function to process image generation with optional image inputs.
    
    Args:
        update: Telegram update
        context: Telegram context
        prompt: Text prompt from user
        images: List of PIL Image objects (can be empty)
    """
    chat_id = update.effective_chat.id
    user_id = update.effective_user.id
    
    # Log the user's prompt
    log_conversation(
        user_id, "create_photo", "user_prompt", prompt,
        image_count=len(images)
    )
    
    # Start animation task
    animation_task = asyncio.create_task(run_loading_animation(context, chat_id))
    
    try:
        # Analyze user intent using Gemma 3 12B classifier
        intent = await analyze_user_intent(prompt, images)
        
        logging.info(f"[CreatePhoto] Intent analysis: CTR={intent['wants_ctr_improvement']}")
        
        # Build enhanced prompt based on classification
        enhanced_prompt = prompt
        enhancements_applied = []
        
        if intent['wants_ctr_improvement']:
            enhanced_prompt += CTR_ENHANCEMENT_PROMPT
            enhancements_applied.append("CTR optimization")
            logging.info("[CreatePhoto] Added CTR optimization enhancement")
        
        # Log the full enhanced prompt when enhancements are applied
        if enhancements_applied:
            logging.info(f"[CreatePhoto] Enhancements applied: {', '.join(enhancements_applied)}")
            logging.info(f"[CreatePhoto] === FULL ENHANCED PROMPT START ===")
            logging.info(f"{enhanced_prompt}")
            logging.info(f"[CreatePhoto] === FULL ENHANCED PROMPT END ===")
        
        model = genai.GenerativeModel(MODEL_NAME)
        logging.info(f"[CreatePhoto] Generating with prompt: {prompt}, images: {len(images)}")
        
        # Build the content for multimodal input
        # For google.generativeai, we pass images and text directly in a list
        if images:
            # Multi-modal: images + enhanced text
            content = images + [enhanced_prompt]
        else:
            # Text-only
            content = enhanced_prompt
        
        # Generate content
        # Note: Aspect ratio is specified in the prompt text (CTR_ENHANCEMENT_PROMPT includes "3:4")
        # The older google.generativeai SDK doesn't support image_generation_config
        if intent['wants_ctr_improvement']:
            logging.info("[CreatePhoto] CTR mode - aspect ratio specified in prompt text")
        response = await model.generate_content_async(content)
        
        # Stop animation before sending results
        animation_task.cancel()
        try:
            await animation_task
        except asyncio.CancelledError:
            pass

        has_content = False

        # Check for image parts
        if hasattr(response, 'parts'):
            for part in response.parts:
                if hasattr(part, 'inline_data') and part.inline_data:
                    logging.info(f"[CreatePhoto] Found image with mime_type: {part.inline_data.mime_type}")
                    image_data = part.inline_data.data
                    
                    caption_text = "üé® –í–∞—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ!"
                    
                    # Send as photo for quick preview (Telegram will compress)
                    await context.bot.send_photo(
                        chat_id=chat_id, 
                        photo=io.BytesIO(image_data),
                        caption=caption_text,
                        parse_mode="Markdown"
                    )
                    
                    # Send as document for full quality
                    await context.bot.send_document(
                        chat_id=chat_id,
                        document=io.BytesIO(image_data),
                        filename="generated_image.png",
                        caption="üì• –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –∫–∞—á–µ—Å—Ç–≤–µ"
                    )
                    has_content = True
                    
                    # Deduct balance and log successful generation
                    new_balance = deduct_balance(user_id, "create_photo")
                    log_conversation(
                        user_id, "create_photo", "bot_image_generated", prompt,
                        image_count=len(images),
                        tokens_used=TOKEN_COSTS["create_photo"],
                        success=True
                    )
                    logging.info(f"[CreatePhoto] Deducted {TOKEN_COSTS['create_photo']} tokens from user {user_id}, new balance: {new_balance}")

        # Check for text response
        try:
            if response.text:
                await context.bot.send_message(chat_id=chat_id, text=response.text)
                has_content = True
                
                # Deduct token for text response (if image wasn't already generated)
                if not any(hasattr(part, 'inline_data') and part.inline_data for part in response.parts if hasattr(response, 'parts')):
                    new_balance = update_user_balance(user_id, -1)
                    log_conversation(
                        user_id, "create_photo", "bot_text_response", prompt,
                        image_count=len(images),
                        tokens_used=1,
                        success=True
                    )
                    logging.info(f"[CreatePhoto] Text response - Deducted 1 token from user {user_id}, new balance: {new_balance}")
        except ValueError:
            pass

        if not has_content:
            await context.bot.send_message(
                chat_id=chat_id, 
                text="‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
            )
        
    except Exception as e:
        # Ensure animation is stopped on error
        if not animation_task.done():
            animation_task.cancel()
            try:
                await animation_task
            except asyncio.CancelledError:
                pass
                
        logging.error(f"[CreatePhoto] Error: {e}", exc_info=True)
        await context.bot.send_message(chat_id=chat_id, text=f"‚ùå –û—à–∏–±–∫–∞: {e}")
        
        # Log the error
        log_conversation(
            user_id, "create_photo", "error", str(e),
            image_count=len(images),
            success=False
        )
